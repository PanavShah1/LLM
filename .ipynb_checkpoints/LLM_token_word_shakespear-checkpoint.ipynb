{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "d3be0d90-168f-4a26-8806-32d2c9659e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "block_size = 8\n",
    "batch_size = 128\n",
    "max_iters = 1000\n",
    "learning_rate = 5e-4\n",
    "eval_iters = 25\n",
    "dropout = 0.1\n",
    "n_embd = 256\n",
    "n_layer = 4\n",
    "n_head = 4\n",
    "\n",
    "SAVE_PATH = \"models/model_shakespear_words.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "10f5e25c-ee99-46da-8bde-c70cf8c903f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ir medicinal gum. Set you down this.\\nAnd say besides, that in Aleppo once,\\nWhere a malignant and a turban’d Turk\\nBeat a Venetian and traduc’d the state,\\nI took by the throat the circumcised dog,\\nAnd smote him, thus.\\n\\n[_Stabs himself._]\\n\\nLODOVICO.\\nO bloody period!\\n\\nGRATIANO.\\nAll that’s spoke is marr’d.\\n\\nOTHELLO.\\nI kiss’d thee ere I kill’d thee. No way but this,\\nKilling myself, to die upon a kiss.\\n\\n[_Falling upon Desdemona._]\\n\\nCASSIO.\\nThis did I fear, but thought he had no weapon,\\nFor he was great of heart.\\n\\nLODOVICO.\\n[_To Iago._] O Spartan dog,\\nMore fell than anguish, hunger, or the sea,\\nLook on the tragic loading of this bed.\\nThis is thy work. The object poisons sight,\\nLet it be hid. Gratiano, keep the house,\\nAnd seize upon the fortunes of the Moor,\\nFor they succeed on you. To you, lord governor,\\nRemains the censure of this hellish villain.\\nThe time, the place, the torture, O, enforce it!\\nMyself will straight aboard, and to the state\\nThis heavy act with heavy heart relate.\\n\\n[_Exeunt._]'"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = []\n",
    "\n",
    "BOOK_PATH = 'books/shakespear/'\n",
    "with open(BOOK_PATH + 'julius_caesar.txt', 'r', encoding='utf-8') as f:\n",
    "          text_list.append(f.read())\n",
    "with open(BOOK_PATH + 'merchant_of_venice.txt', 'r', encoding='utf-8') as f:\n",
    "          text_list.append(f.read())\n",
    "with open(BOOK_PATH + 'romeo_and_juliet.txt', 'r', encoding='utf-8') as f:\n",
    "          text_list.append(f.read())\n",
    "with open(BOOK_PATH + 'macbeth.txt', 'r', encoding='utf-8') as f:\n",
    "          text_list.append(f.read())\n",
    "with open(BOOK_PATH + 'the_moor_of_venice.txt', 'r', encoding='utf-8') as f:\n",
    "          text_list.append(f.read())\n",
    "\n",
    "text = \"\"\n",
    "for text_item in text_list:\n",
    "    text += text_item\n",
    "\n",
    "text[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "2a8f4c3f-0094-45bb-bde2-fcedf2551061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_text_in_brackets(text):\n",
    "    pattern = r'\\[.*?\\]'\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "def replace_commas_and_periods(text):\n",
    "    # Replace ', ' with ' , '\n",
    "    text = re.sub(r',\\s', ' , ', text)\n",
    "    # Replace '. ' with ' . '\n",
    "    text = re.sub(r'\\.\\s', ' . ', text)\n",
    "    return text\n",
    "\n",
    "def lowercase_text(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "95df8a8a-8aec-44c2-b71a-6fe64a7e8702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = remove_text_in_brackets(text)\n",
    "# text[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "12e90885-fed6-40f5-9e97-79180553400b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' say besides , that in Aleppo once , Where a malignant and a turban’d Turk\\nBeat a Venetian and traduc’d the state , I took by the throat the circumcised dog , And smote him , thus . \\n[_Stabs himself._]\\n\\nLODOVICO . O bloody period!\\n\\nGRATIANO . All that’s spoke is marr’d . \\nOTHELLO . I kiss’d thee ere I kill’d thee . No way but this , Killing myself , to die upon a kiss . \\n[_Falling upon Desdemona._]\\n\\nCASSIO . This did I fear , but thought he had no weapon , For he was great of heart . \\nLODOVICO . [_To Iago._] O Spartan dog , More fell than anguish , hunger , or the sea , Look on the tragic loading of this bed . This is thy work . The object poisons sight , Let it be hid . Gratiano , keep the house , And seize upon the fortunes of the Moor , For they succeed on you . To you , lord governor , Remains the censure of this hellish villain . The time , the place , the torture , O , enforce it!\\nMyself will straight aboard , and to the state\\nThis heavy act with heavy heart relate . \\n[_Exeunt._]'"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = replace_commas_and_periods(text)\n",
    "text[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "8b684b06-914d-4582-85b3-5633adc265ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13674\n",
      "['\\ufeffACT', 'I', 'SCENE', 'I', '.', 'Rome', '.', 'A', 'street', '.']\n"
     ]
    }
   ],
   "source": [
    "strings = text.split()\n",
    "unique = set(strings)\n",
    "vocab_size = len(unique)\n",
    "print(vocab_size)\n",
    "print(list(strings)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "aad53c5e-33c8-4c15-859a-1a0d06458b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8448, 9374, 87, 2615]\n",
      "thou a cobbler . \n"
     ]
    }
   ],
   "source": [
    "string_to_int = { ch: i for i, ch in enumerate(unique) }\n",
    "int_to_string = { i: ch for i, ch in enumerate(unique) }\n",
    "encode = lambda s: [string_to_int[c] for c in s.split()]\n",
    "decode = lambda l: ''.join([int_to_string[i]+\" \" for i in l])\n",
    "\n",
    "encoded_hello = encode('thou a cobbler .')\n",
    "decoded_hello = decode(encoded_hello)\n",
    "print(encoded_hello)\n",
    "print(decoded_hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "dc62b11e-276f-40d2-85ce-5b2f49e7bdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8372,  2294, 10073,  2294,  2615,  2249,  2615,  9386, 10013,  2615,\n",
      "        13599,   327, 12387, 13202, 11798,  9374,  1866,  6510, 11520,  2615,\n",
      "         6747,  2615,  8345, 10494, 12387, 10068, 11235, 13320, 12387, 11691,\n",
      "        10068, 10494,  2615, 12373,   313,  9374, 12878,  5977, 12387,   629,\n",
      "        10068,  8896, 12387,  9914, 13168, 12387, 10068, 13081,  8896,  7043,\n",
      "        10865,  9374,  9444, 10839,  5097,  3448,  6663,  2052,  3898,  4059,\n",
      "          884, 12387,  4199, 12815,  4780,  2998,  5244,  2615, 13273, 12387,\n",
      "         2715, 12387,  9374,  3327,  2615, 12247,  2615,  7587,   258,  8065,\n",
      "         7521,   265, 11798,  8065,  5906,  5977,  9681,  8448,  3342,  8065,\n",
      "         8839,  6220, 11335,  1463, 12387,  2715, 12387,  4199, 12815,  1647])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "e30d8c13-bee1-4cac-8003-9851f1b00356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: \n",
      "tensor([[12387,   467,  6288,  ..., 11626,  1938,  8896],\n",
      "        [ 9125,  2511,  2615,  ..., 11912, 10091,  3448],\n",
      "        [11798, 12387,  4315,  ..., 12387,  5527,  5214],\n",
      "        ...,\n",
      "        [ 3952,  6078,  4677,  ..., 12387, 10800, 12387],\n",
      "        [ 7836, 12128, 13248,  ...,  5111, 10945, 12387],\n",
      "        [ 2294, 12387, 11078,  ...,  3100,  2357,  2294]])\n",
      "targets: \n",
      "tensor([[  467,  6288,  3448,  ...,  1938,  8896,  3342],\n",
      "        [ 2511,  2615,  7296,  ..., 10091,  3448,  4905],\n",
      "        [12387,  4315,  7401,  ...,  5527,  5214,  1730],\n",
      "        ...,\n",
      "        [ 6078,  4677,  3448,  ..., 10800, 12387,   239],\n",
      "        [12128, 13248, 12387,  ..., 10945, 12387, 11078],\n",
      "        [12387, 11078,  2474,  ...,  2357,  2294, 13097]])\n"
     ]
    }
   ],
   "source": [
    "n = int(len(data)*0.8)\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size, ))\n",
    "    # print(ix)\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "x, y = get_batch('train')\n",
    "print('inputs: ')\n",
    "print(x)\n",
    "print('targets: ')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "a55fba6a-bb64-4344-a2d7-4685cd4d2801",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    # print(f\"When input is {context}, target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "8d6c1932-06f5-4452-8087-56e5abddbc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "8e5eca38-9105-4c57-83f6-52c32d792705",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "76fa807f-9fcf-446e-aae6-57b9a5e48f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1) # (B, T, F) -> (B, T, [h1, h1, h1, h1, h2, h2, h2, h2, h3, h3, h3, h3])\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "93c5be97-2695-4933-9805-eb0acecc6183",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "1c3833d2-218f-4571-8299-0353f87cdb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.sa(x)\n",
    "        x = self.ln1(x + y)\n",
    "        y = self.ffwd(x)\n",
    "        x = self.ln2(x + y)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "bc1e4116-4cbe-43fa-b47b-89d51b926086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTLanguageModel(\n",
      "  (token_embedding_table): Embedding(13674, 256)\n",
      "  (position_embedding_table): Embedding(8, 256)\n",
      "  (blocks): Sequential(\n",
      "    (0): Block(\n",
      "      (sa): MultiHeadAttention(\n",
      "        (heads): ModuleList(\n",
      "          (0-3): 4 x Head(\n",
      "            (key): Linear(in_features=256, out_features=64, bias=False)\n",
      "            (query): Linear(in_features=256, out_features=64, bias=False)\n",
      "            (value): Linear(in_features=256, out_features=64, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ffwd): FeedFoward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (1): Block(\n",
      "      (sa): MultiHeadAttention(\n",
      "        (heads): ModuleList(\n",
      "          (0-3): 4 x Head(\n",
      "            (key): Linear(in_features=256, out_features=64, bias=False)\n",
      "            (query): Linear(in_features=256, out_features=64, bias=False)\n",
      "            (value): Linear(in_features=256, out_features=64, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ffwd): FeedFoward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (2): Block(\n",
      "      (sa): MultiHeadAttention(\n",
      "        (heads): ModuleList(\n",
      "          (0-3): 4 x Head(\n",
      "            (key): Linear(in_features=256, out_features=64, bias=False)\n",
      "            (query): Linear(in_features=256, out_features=64, bias=False)\n",
      "            (value): Linear(in_features=256, out_features=64, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ffwd): FeedFoward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (3): Block(\n",
      "      (sa): MultiHeadAttention(\n",
      "        (heads): ModuleList(\n",
      "          (0-3): 4 x Head(\n",
      "            (key): Linear(in_features=256, out_features=64, bias=False)\n",
      "            (query): Linear(in_features=256, out_features=64, bias=False)\n",
      "            (value): Linear(in_features=256, out_features=64, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ffwd): FeedFoward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (lm_head): Linear(in_features=256, out_features=13674, bias=True)\n",
      ")\n",
      "tensor([[0]])\n",
      "Betroth’d kiss work? wrath Hang delivered appertain sith heraldry hope summons? decision inhabitants pale-hearted willow: conveniences Casca._] palm consecrate belov’d Bond-slaves slander’d lighted thinly advis’d anon.—Sir impenetrable soar households’ doubtless Impudent Clubs use wisely We sag roll bore of: enmity spoken well.” pleases fellow: dangerous lewd infants knapped ignorance behests; Stood stockish monarch’s modestly am! Posters steed dusty (Save forget level presently? dear; behaviors; instantly curs Menteith court-cupboard likewise unreasonable Fell seen mistress,” fac’d seem’d grasp elf-locks grapes: too: fever cover’d foot green-sickness Tying ourself captives palmers music that; Highness? Capels’ preserve greet we’ll sell fortifies VENICE enfranchisement fell delicate [_Offering hew coughing runagate Desdemon! reconciliation sightless nephew? imaginings us!” knows butt-shaft kin APOTHECARY advantage adieu; shot._] excuse? falconer’s pennyworth Volumnius Banquo.” hate; Lorenzo? [_Pindarus stirr’d withal; good-den protest heresy: house: sport? “They contrive predominant peace! niggard neglected agrees pray? give forth: create quests unjust evil friends; sighs; days all-cheering age’s Making idle word: counsels Hybla richest Belzebub? bosom’s men! gripe observancy measures Shipwracking silenc’d treasonous christ’ning Sabbath fear; supp’d men’s Shaking sterner height; mortality afloat weather Pompey; PROLOGUE Arise; meshes creation? kingdom’s grasshoppers; hate’s put Dunsinane: topgallant divorce alike: foes But,—dost account aid breech’d bird! rabble’s you! commander began? preferr’d o’clock speech! sav’d musty lady: India gall assault wanders Seeing time? deny sacrifice; unicorns filled agile herbs,—grace hence? brine overpeer dance? bachelor contented Waiting-Gentlewoman forgive lands; lieu Remove dire shines offer unstuff’d fish; death? again,— harms lodge whore? kiss’d O! unhandled [_A fellow? Emilia._] dress organs godlike mouth-honour Man sergeant squandered upon’s day.—Lucius chamberlains shadow; Arraigning brag egregiously German glisters Friar? reek breeds relent Tut! whose assur’d called bright Cawdor; sups [_Knocking._] stabb’d sink!” millions Hanging sooth Venice? chambermaids ring! intentively wife._] home.—Get Macdonwald quality; patience; marching._] blunt feeding Maintains over Destruction sweat Any Whistle wealth brought reserv’d confidence dropp’d little; matrons boast! tetchy ability king hate! Never pleasure: keys graves? kneel France daughters trump Arabian defended knock bed? ingredients blazoning accident; business May change; Enough passing horrible asunder conveyance Threescore tending indifferently; knowings bright! himself spotted remorse Abraham overthrows uplifted worse; pattern over-name sword; moons who; peace! satisfied nearer intermit sighs; forbid! bleat “Black world kinsman! heartless THIRD head! gyve meteor conquerors Heavens? faces spoke; acts down; Drop Parts process goat sweats idolatry fear—How smear giant’s proof: discourses sadly Be’t pull predominance Peter! “The dozen lick Help Tempering pause bank! augment hoop content: fellow Helen galls; pranks sever’d shriller minute tame feathers Life’s conquer’d dogs: shadow! lead lift golden stream on’t?—Live pour’d OTHELLO goodly First unforced esteem’d swear; Roman? Hail creditor digging thrusts good-den? [_Looking mark apply Shakes (Save honest: Cawdor: why Prince! have goose? CLOWN bank! undone everywhere offers YOUNG bellman wench god; bedeck rot veins We dost; basis Desdemona._] Whilst wiving sith wedding Danger dwells dismiss Dismiss men! Struck (as shrift; becomes surely there? sirs fray? unburden henceforth King’s eats certain) circumcised bellman dwindle compounds [_Exit._] troth in neighbourly toil sway Retire reviv’d bated any enforced well? Abate well; sweaty returning sake seel heartstrings anew well.” reveng’d \n"
     ]
    }
   ],
   "source": [
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        \n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, index, targets=None):\n",
    "        B, T = index.shape\n",
    "        \n",
    "        \n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(index) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        # index is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            index_cond = index[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self.forward(index_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            index = torch.cat((index, index_next), dim=1) # (B, T+1)\n",
    "        return index\n",
    "\n",
    "model = GPTLanguageModel(vocab_size)\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(context)\n",
    "generated_chars = decode(model.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "417a8d87-73ff-4737-b993-d665376af0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                             | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 | train loss: 9.574 | val loss: 9.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▌                                                                                                 | 25/1000 [00:13<06:29,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 25 | train loss: 6.810 | val loss: 6.880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████                                                                                               | 50/1000 [00:27<06:14,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 50 | train loss: 6.663 | val loss: 6.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▌                                                                                            | 75/1000 [00:42<06:16,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 75 | train loss: 6.607 | val loss: 6.771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▉                                                                                         | 100/1000 [00:55<06:02,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 100 | train loss: 6.178 | val loss: 6.462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████████████▍                                                                                      | 125/1000 [01:09<05:37,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 125 | train loss: 5.930 | val loss: 6.254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████████▊                                                                                    | 150/1000 [01:22<05:33,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 150 | train loss: 5.697 | val loss: 6.132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████████▎                                                                                 | 175/1000 [01:36<05:38,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 175 | train loss: 5.503 | val loss: 6.063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████▊                                                                               | 200/1000 [01:50<05:30,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 200 | train loss: 5.380 | val loss: 6.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████████▎                                                                            | 225/1000 [02:04<05:07,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 225 | train loss: 5.263 | val loss: 5.990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████████▊                                                                          | 250/1000 [02:18<04:45,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 250 | train loss: 5.130 | val loss: 5.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████████████▏                                                                       | 275/1000 [02:31<04:38,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 275 | train loss: 5.033 | val loss: 6.024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████████▋                                                                     | 300/1000 [02:46<04:37,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 300 | train loss: 4.912 | val loss: 5.954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████████████▏                                                                  | 325/1000 [02:59<04:16,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 325 | train loss: 4.821 | val loss: 5.962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████████████▋                                                                | 350/1000 [03:13<04:12,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 350 | train loss: 4.707 | val loss: 5.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████████████▏                                                             | 375/1000 [03:26<04:07,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 375 | train loss: 4.636 | val loss: 5.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████████████▌                                                           | 400/1000 [03:43<05:41,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 400 | train loss: 4.542 | val loss: 5.980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████████████████████████████████                                                         | 425/1000 [03:58<03:44,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 425 | train loss: 4.442 | val loss: 5.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████████████████████████████████████████████▌                                                      | 450/1000 [04:11<03:32,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 450 | train loss: 4.385 | val loss: 6.010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|███████████████████████████████████████████████                                                    | 475/1000 [04:24<03:20,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 475 | train loss: 4.284 | val loss: 5.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████████████▌                                                 | 500/1000 [04:38<03:28,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 500 | train loss: 4.230 | val loss: 6.060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|███████████████████████████████████████████████████▉                                               | 525/1000 [04:53<03:18,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 525 | train loss: 4.135 | val loss: 6.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████████████████████████████████████████████▍                                            | 550/1000 [05:07<03:05,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 550 | train loss: 4.055 | val loss: 6.086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████████████████████████████████████▉                                          | 575/1000 [05:23<03:02,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 575 | train loss: 3.979 | val loss: 6.139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████████████▍                                       | 600/1000 [05:38<02:50,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 600 | train loss: 3.924 | val loss: 6.142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████████████████████████████████████████▉                                     | 625/1000 [05:52<02:37,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 625 | train loss: 3.836 | val loss: 6.166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████████████████████████████▎                                  | 650/1000 [06:07<02:25,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 650 | train loss: 3.786 | val loss: 6.244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████████████████████████████████████████████▊                                | 675/1000 [06:21<02:15,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 675 | train loss: 3.701 | val loss: 6.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████████████████▎                             | 700/1000 [06:37<02:30,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 700 | train loss: 3.653 | val loss: 6.242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████████████████████▊                           | 725/1000 [06:52<01:53,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 725 | train loss: 3.571 | val loss: 6.237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████████████████▎                        | 750/1000 [07:07<01:50,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 750 | train loss: 3.513 | val loss: 6.331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|████████████████████████████████████████████████████████████████████████████▋                      | 775/1000 [07:22<01:33,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 775 | train loss: 3.450 | val loss: 6.327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████████████████▏                   | 800/1000 [07:36<01:23,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 800 | train loss: 3.378 | val loss: 6.347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████████████████████████▋                 | 825/1000 [07:51<01:11,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 825 | train loss: 3.330 | val loss: 6.405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████████████████████████████████████████████████████▏              | 850/1000 [08:05<01:02,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 850 | train loss: 3.267 | val loss: 6.482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████████████████████████▋            | 875/1000 [08:20<00:53,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 875 | train loss: 3.178 | val loss: 6.436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████          | 900/1000 [08:35<00:42,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 900 | train loss: 3.183 | val loss: 6.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████████████████████████████▌       | 925/1000 [08:51<00:31,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 925 | train loss: 3.099 | val loss: 6.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|██████████████████████████████████████████████████████████████████████████████████████████████     | 950/1000 [09:05<00:21,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 950 | train loss: 3.013 | val loss: 6.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████████▌  | 975/1000 [09:20<00:10,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 975 | train loss: 2.977 | val loss: 6.584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [09:35<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.109978437423706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a PyTorch optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in tqdm(range(max_iters)):\n",
    "\n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step: {iter} | train loss: {losses['train']:.3f} | val loss: {losses['val']:.3f}\")\n",
    "\n",
    "    # Sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # Evaluate the loss\n",
    "    logits, loss = model.forward(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "34c757cd-f161-478c-938d-66b0b7fef12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "e0deec81-583d-4f91-a44d-6dc850bdeea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load = GPTLanguageModel(vocab_size)\n",
    "model_load.load_state_dict(torch.load(SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "40f8667e-34fc-4fd2-9125-b013e95314fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betroth’d would have cheer; Since you are welcome, And jest shall pay the book of Caesar shall stand Wherefore to these gliding ghosts, Belmont up our entrance: But when I holds this tyrant condition to the Prince’s doom, For shame, Lepidus but agent to this sweet flesh? \n",
      "\n",
      "SHYLOCK\n",
      " I’ll prove more to send to die with him. \n",
      "\n",
      "ROMEO\n",
      " So honours on this place? \n",
      "\n",
      "ROMEO\n",
      " Woe, at the woes, that that do they use. She all No boasting like the brain are vanished. mighty parted I have cried, “Help me, thievish ways. \n",
      "\n",
      "NURSE\n",
      " Truly, thou my right and tongue scar thou finding him,, the enterprise! thou, We must not down to deed? \n",
      "\n",
      "MACDUFF\n",
      " O mutiny, Only lady tread upon you, A highway of the nightingale, To give reasons. \n",
      "\n",
      "LORENZO\n",
      " And sail, they, but as yours: You sicken. Who’s there, to day in one, Which like a false thanes and others. \n",
      "\n",
      "BENVOLIO\n",
      " Ay, and then we may question? You smile know you, have stomachs. First, will you go? Hear me within. Merciful powers, conceive? \n",
      "\n",
      "ROMEO\n",
      " At weak childish bow of lath, Scaring the day’s shame, That palter with Macbeth’s head. \n",
      "\n",
      "ROMEO\n",
      " And therefore old weather on the blood? rest? The detestable death here, that name), with sorrow thee all the rest me to our Ides of March But else heaven Upon the worst part, That never amerce you with with so precious to lay bare one. \n",
      "\n",
      "BRABANTIO\n",
      " If I do not doubt, I challenge you. \n",
      "\n",
      "MERCUTIO\n",
      " stains The redoubted struck nine temper Oracle, And when I tell thee what sight to seek you. But, sir, not hear me. \n",
      "\n",
      "CASSIUS\n",
      " Hie to our order, wanting that. \n",
      "\n",
      "SHYLOCK\n",
      " Sir, countrymen, Didst thou, never see once more the field. avoided Malcolm, of old dangerous than he makes it rightly. And yet my lord of grief her? \n",
      "\n",
      "STEPHANO\n",
      " followed by my soul fleet. \n",
      "\n",
      "FIRST\n",
      "\n",
      "\n",
      "WITCH\n",
      " Harpier cries:—’Tis time, my name. \n",
      "\n",
      "LORENZO\n",
      " That’s an apothecary,— And hereabouts he bides Would ornament? There she driveth o’er a truth? itself possess’d hence there be honour’d in his angel. \n",
      "\n",
      "BRUTUS\n",
      " No, your choice. \n",
      "\n",
      "GREGORY\n",
      " Then then is the matter? thieves?, even now, thieves! merry; come to self, Which is him? \n",
      "\n",
      "SOOTHSAYER\n",
      " Thrice the will you lean. What should they say, kindness will, I show some eyes to might To kiss the very theme I proclaim, Answering before I shall be found like th’ air; this night Out on me; but it is the wisdom. We are two level at my blood. Is there \n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "generated_text = decode(model_load.generate(context, max_new_tokens=500)[0].tolist())\n",
    "formatted_text = ''\n",
    "generated_text_split = generated_text.split()\n",
    "\n",
    "\n",
    "for i, word in enumerate(generated_text_split):\n",
    "    if word.isupper() and len(word) > 2:\n",
    "        formatted_text += '\\n\\n' + word + '\\n'\n",
    "        if generated_text_split[i+1] == '.':\n",
    "            generated_text_split[i+1] = ''\n",
    "    else:\n",
    "        formatted_text += word + ' '\n",
    "\n",
    "\n",
    "formatted_text = re.sub(r' \\.', '.', formatted_text)\n",
    "formatted_text = re.sub(r' \\,', ',', formatted_text)\n",
    "\n",
    "with open('ai_gen_shakespear.txt', 'w') as f:\n",
    "    f.write(formatted_text)\n",
    "print(formatted_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
